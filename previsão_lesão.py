# -*- coding: utf-8 -*-
"""Previsão_lesão.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NWBEh34tzLnOQ-V1REqWAzqyivf7PwgG

Projeto: Previsão de Risco de Lesão Esportiva
Autor: Lucas Resende
Descrição:
Modelo de Machine Learning para previsão de lesões esportivas
com base em dados fisiológicos e de carga de treino.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier
from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix

# Simulando dados de 200 atletas
np.random.seed(42)
n = 200

df = pd.DataFrame({
    'treino_duracao': np.random.randint(40, 120, n),             # minutos de treino
    'freq_cardiaca': np.random.randint(120, 190, n),             # bpm médio
    'PSE': np.random.randint(4, 10, n),                          # percepção subjetiva de esforço (0-10)
    'dist_percorrida': np.random.uniform(3, 12, n).round(2),     # distância percorrida (km)
    'dias_desde_ultima_lesao': np.random.randint(0, 60, n),      # dias desde última lesão
})

# Criar uma variável dependente (lesão) com base em padrões realistas achados nas pesquisas realizadas pela UFMG e USP
df['lesao'] = ((df['freq_cardiaca'] > 165) &
               (df['PSE'] > 7) &
               (df['dias_desde_ultima_lesao'] < 15)).astype(int)

print("Visualização inicial dos dados:")
print(df.head())

print("\nEstatísticas descritivas:")
print(df.describe())

# Correlação entre variáveis
plt.figure(figsize=(8,6))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title("Correlação entre variáveis")
plt.show()

#Pré-processamento
X = df.drop('lesao', axis=1)
y = df['lesao']

# Divisão treino/teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Normalização
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#Treinamneto dos modelos
modelos = {
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "Bagging": BaggingClassifier(random_state=42),
    "Boosting": GradientBoostingClassifier(random_state=42)
}

resultados = []

for nome, modelo in modelos.items():
    modelo.fit(X_train, y_train)
    y_pred = modelo.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_pred)
    f1 = classification_report(y_test, y_pred, output_dict=True)['weighted avg']['f1-score']
    resultados.append([nome, acc, auc, f1])

#Resultados Comparativos
df_resultados = pd.DataFrame(resultados, columns=["Modelo", "Acurácia", "AUC", "F1-score"])
print("\nDesempenho dos Modelos:")
print(df_resultados.sort_values(by="AUC", ascending=False))

plt.figure(figsize=(8,5))
sns.barplot(x="Modelo", y="AUC", data=df_resultados, palette="Blues_d")
plt.title("Comparação de Desempenho dos Modelos (AUC)")
plt.show()

#Matriz de confusão do melhor modelo
melhor_modelo = GradientBoostingClassifier(random_state=42)
melhor_modelo.fit(X_train, y_train)
y_pred = melhor_modelo.predict(X_test)

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Greens')
plt.title("Matriz de Confusão - Modelo Boosting")
plt.xlabel("Previsto")
plt.ylabel("Real")
plt.show()

print("\nRelatório de Classificação (Boosting):")
print(classification_report(y_test, y_pred))